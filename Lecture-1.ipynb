{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduction to machine learning: definitions, problem statements and prominent achievements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Approximate syllabus\n",
    "\n",
    "- Introduction\n",
    "- Metric methods\n",
    "- Logistic regression\n",
    "- SVM\n",
    "- Ensembles: trees and forests\n",
    "- Neural network\n",
    "- EM-algorithm\n",
    "- Markov chains\n",
    "- Regularization\n",
    "- X learning\n",
    "- Other selected topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Resources\n",
    "\n",
    "- Google\n",
    "- Books\n",
    "    - [Pattern Recognition and Machine Learning by C. Bishop](http://users.isr.ist.utl.pt/~wurmd/Livros/school/Bishop%20-%20Pattern%20Recognition%20And%20Machine%20Learning%20-%20Springer%20%202006.pdf)\n",
    "    - [Machine Learning: Probabilistic Perspective by K. Murphy](https://mitpress.mit.edu/books/machine-learning-0)\n",
    "    - [Elements of Statistical Learning by T. Hastie](https://web.stanford.edu/~hastie/Papers/ESLII.pdf)\n",
    "    - [Deep Learning by I. Goodfellow](http://www.deeplearningbook.org/)\n",
    "- Related courses\n",
    "    - Coursera: [1](https://www.coursera.org/learn/vvedenie-mashinnoe-obuchenie), [2](https://www.coursera.org/learn/machine-learning)\n",
    "    - [Lecture notes by K.V. Vorontsov](http://www.machinelearning.ru/wiki/index.php?title=%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5_%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5_%28%D0%BA%D1%83%D1%80%D1%81_%D0%BB%D0%B5%D0%BA%D1%86%D0%B8%D0%B9%2C_%D0%9A.%D0%92.%D0%92%D0%BE%D1%80%D0%BE%D0%BD%D1%86%D0%BE%D0%B2%29)\n",
    "    - [MSU CMC course](http://www.machinelearning.ru/wiki/index.php?title=%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5_%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5_%28%D1%81%D0%B5%D0%BC%D0%B8%D0%BD%D0%B0%D1%80%D1%8B%2C_%D0%92%D0%9C%D0%9A_%D0%9C%D0%93%D0%A3%29)\n",
    "    - [HSE course](http://wiki.cs.hse.ru/%D0%9C%D0%B0%D0%B9%D0%BD%D0%BE%D1%80_%D0%98%D0%BD%D1%82%D0%B5%D0%BB%D0%BB%D0%B5%D0%BA%D1%82%D1%83%D0%B0%D0%BB%D1%8C%D0%BD%D1%8B%D0%B9_%D0%B0%D0%BD%D0%B0%D0%BB%D0%B8%D0%B7_%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85/%D0%92%D0%B2%D0%B5%D0%B4%D0%B5%D0%BD%D0%B8%D0%B5_%D0%B2_%D0%B0%D0%BD%D0%B0%D0%BB%D0%B8%D0%B7_%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85)\n",
    "- Repository with [lectures](https://github.com/amkatrutsa/intro_ml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Required background\n",
    "\n",
    "- Linear algebra\n",
    "- Optimization\n",
    "- Probability theory and statistics\n",
    "- Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Main tools\n",
    "\n",
    "- [Anaconda distribution](https://www.anaconda.com/download/) with Python 3 and:\n",
    "    - Jupyter Notebook\n",
    "    - NumPy & SciPy \n",
    "    - scikit-learn\n",
    "    - pandas\n",
    "    - matplotlib\n",
    "    - seaborn\n",
    "- [TensorFlow](https://www.tensorflow.org/) or related framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Related research fields\n",
    "\n",
    "- Artificial Intelligence\n",
    "- Statistical Data Analysis\n",
    "- Pattern Recognition\n",
    "- Statistical Learning\n",
    "- Data Mining\n",
    "- Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Objectives\n",
    "\n",
    "- Academia\n",
    "    - Propose idea\n",
    "    - Prove some general facts about algorithm\n",
    "    - Investigate model data sets\n",
    "    - Evaluation function\n",
    "- Industry\n",
    "    - Solve poorly stated real bussiness problem\n",
    "    - Scalability is crucial\n",
    "    - Usually available large or huge data set\n",
    "    - Evaluation is not directly related to stated problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Definitions and concepts\n",
    "\n",
    "- $X$ - set of samples\n",
    "- $Y$ - set of outputs in case of supervised learning\n",
    "- Other types of learning may not require $Y$\n",
    "- Target function $y: X \\to Y$\n",
    "- Given *training set* $\\{x_1, \\dots, x_{m}\\} \\subset X$ and *known outputs* $y_i = y(x_i), \\; i = 1,\\dots, m$\n",
    "- Find *algorithm* or *decision function* $a: X \\to Y$ which approximates $y$ over the whole $X$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Questions\n",
    "\n",
    "1. How represent $X$ and $Y$?\n",
    "2. How define $a$?\n",
    "3. What does \"approximate\" mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Samples representation: features\n",
    "\n",
    "- $f_j: X \\to D_j$, $j = 1,\\dots,n$ is feature map\n",
    "- Features types\n",
    "    - binary: $D_j = \\{0, 1\\}$\n",
    "    - categorical: $|D_j| < \\infty$\n",
    "    - ordinal: $|D_j| < \\infty$ and $D_j$ is ordered\n",
    "    - continuous: $D_j = \\mathbb{R}^n$\n",
    "- Design matrix\n",
    "$$\n",
    "F = \\| f_j(x_i) \\|_{m \\times n}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Outputs representation\n",
    "\n",
    "- $Y = \\{0,1 \\}$ &mdash; binary classification\n",
    "- $Y = \\{0,1, \\dots, M \\}$ &mdash; multiclass classification\n",
    "- $Y = \\mathbb{R}$ &mdash; regression\n",
    "- $Y$ is a finite ordinal set &mdash; ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### All models are wrong but some are useful\n",
    "\n",
    "- Predictive model is a parametric family of functions\n",
    "$$\n",
    "A = \\{ g(x, \\theta) \\; | \\; \\theta \\in \\Theta \\},\n",
    "$$\n",
    "where $g(x, \\theta): X \\times \\Theta \\to Y$ is a fix function and $\\Theta$ is feasible set of parameters.\n",
    "- Example: linear model\n",
    "    - For regression and ranking \n",
    "    $$\n",
    "    g(x, \\theta) = \\sum_{j=1}^n \\theta_j f_j(x)\n",
    "    $$ \n",
    "    - For binary classification \n",
    "    $$\n",
    "    g(x, \\theta) = \\mathrm{sign}\\left( \\sum_{j=1}^n \\theta_j f_j(x) \\right)\n",
    "    $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Learning algorithm\n",
    "\n",
    "- Learning algorithm $\\mu$ maps given training set $D = (X, Y)^{m}$ to algorithm $a \\in A$\n",
    "$$\n",
    "\\mu \\; : \\; D \\to a  \n",
    "$$\n",
    "- Training step\n",
    "$$\n",
    "a = \\mu(D)\n",
    "$$\n",
    "- Testing step\n",
    "$$\n",
    "\\hat{Y} = a(\\hat{X})\n",
    "$$\n",
    "- Validation step: check quality of $\\hat{Y}$\n",
    "- Application step: use the best $a$ for new real data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Loss function\n",
    "\n",
    "- How check the quality of our algorithm $a$?\n",
    "- Introduce some function $L(a, x_i)$ which gives the error of algorithm $a$ given the sample $x_i$\n",
    "    - Classification \n",
    "    $$\n",
    "    L(a, x_i) = [a(x_i) \\neq y(x_i)]\n",
    "    $$\n",
    "    - Regression\n",
    "    $$\n",
    "    L(a, x_i) = (a(x_i) - y(x_i))^2\n",
    "    $$\n",
    "- Empirical risk\n",
    "$$\n",
    "Q(a, X) = \\frac{1}{|X|} \\sum_{x_i \\in X} L(a, x_i)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### From learning to optimization\n",
    "\n",
    "- We search algorithm that minimizes empirical risk over training set...\n",
    "$$\n",
    "a^* = \\arg\\min_{a \\in A} Q(a, X)\n",
    "$$\n",
    "but not too much. Why?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Overfitting and generatlization ability\n",
    "\n",
    "- Statistical Learning Theory is about this: [VC-dimension](https://en.wikipedia.org/wiki/VC_dimension), [Rademacher complexity](https://en.wikipedia.org/wiki/Rademacher_complexity) and other...\n",
    "- Overfitting is a phenomenon, whrn train loss significantly decreases and test loss increases\n",
    "- Model complexity is important\n",
    "- Picture from [here](https://www.analyticsvidhya.com/blog/2015/02/avoid-over-fitting-regularization/)\n",
    "<p align=\"center\"> \n",
    "<img src=\"./fig/underfitting-overfitting.png\">\n",
    "</p>\n",
    "- Real case I will add later..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Empirical estimation of generalization ability \n",
    "\n",
    "- Hold out\n",
    "    - Split train set \n",
    "    $$\n",
    "    X = X^k \\sqcup X^l\n",
    "    $$\n",
    "    - Subset $X^l$ is used for training, $X^k$ is used for testing\n",
    "    $$\n",
    "    Q(\\mu(X^l), X^k) \\to \\min\n",
    "    $$\n",
    "- Leave-one-out\n",
    "$$\n",
    "\\frac{1}{m}\\sum_{i=1}^m L(\\mu(X \\backslash  x_i), x_i) \\to \\min\n",
    "$$\n",
    "- Cross validation\n",
    "    - Train set is splitted \n",
    "    $$\n",
    "    X = \\bigsqcup_{l=1}^k X^l\n",
    "    $$\n",
    "    - Every $X^l$ is used as test subset, other blocks are used as train set\n",
    "    $$\n",
    "    \\frac{1}{k} \\sum_{l=1}^k L(\\mu(X \\backslash X^l), X^l) \\to \\min\n",
    "    $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Workflow\n",
    "\n",
    "- Dive into data and informal problem \n",
    "- Data preprocessing and feature engineering\n",
    "- Create model\n",
    "- From learning problem to optimization problem\n",
    "- Solving optimization and overfitting problems\n",
    "- Evaluate the quality of the final model\n",
    "- Inroducing in production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Examples of real cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Achievements and breakthroughs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Reinforcement learning\n",
    "\n",
    "<img src=\"./fig/reinforcement.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Representation learning\n",
    "<img src=\"./fig/tsne_mnist.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Recommender system: NetFlix Prize\n",
    "\n",
    "<img src=\"./fig/netflix.jpg\";width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Deep learning\n",
    "\n",
    "<img src=\"./fig/dl_detection.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recap\n",
    "\n",
    "- Main definitions\n",
    "- Problem statements\n",
    "- Overfitting and generalization ability\n",
    "- Workflow\n",
    "- Real cases"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [conda env:p3]",
   "language": "python",
   "name": "conda-env-p3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
